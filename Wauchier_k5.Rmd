---
title: "Wauchier"
author: "JB Camps"
date: "23 novembre 2018 / 30 juin 2019 (Paris, Rome, Turin, Eurostar, )"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<!-- TODO: 
- remove all punctuation;
- concaténer textes trop courts pour gagner un peu de fiabilité?
- groupe 41-45: est-ce que ça mériterait d'être un autre légendier ? Car pas forcément dans C.
-->


# Preparations 

## Load libraries and functions

```{r}
library("cluster")
library("dendextend")
source("functions.R")
```


# Corpus description and selection

## Load data

```{r}
# Get data with Stylo
# data = stylo::load.corpus.and.parse(corpus.dir = "../dh-meier-data/output/transkribus/tokenized/boudams/", features = "w", ngram.size = 1, preserve.case = FALSE)
# Get freq lists
#data = stylo::make.table.of.frequencies(corpus = data, features = unique(sort(unlist(data))), relative = FALSE)
# Write it
#write.csv(as.matrix(data), "data/transkr_expanded_words.csv")
data = read.csv("data/transkr_expanded_words.csv", header = TRUE, row.names = 1)
data = t(data)
```

## Text lengths

```{r}
nwords = colSums(data)
summary(nwords)
boxplot(nwords)
boxplot(nwords)$out
head(sort(nwords), n = 15)

toKeep = colnames(data)[nwords > 1000]

toKeep = toKeep[grep("Bestiaire", toKeep, invert = TRUE)]

# nwords = colSums(data[, toKeep])
# summary(nwords)
# boxplot(nwords)
# boxplot(nwords)$out
# head(sort(nwords), n = 15)

# Testing this # Remove it after
# toKeep = toKeep = toKeep[!toKeep == "60_Ano_Leg-B_NA_NA_NA_Antechriste"]

df = as.data.frame(nwords)

ggplot(df, aes(x="", y=nwords)) + geom_violin() + geom_boxplot(width=0.3) +  theme(axis.text.y = element_text(size = rel(1.4)), axis.title = element_text(size = rel(1.4))) + xlab("Est. length in words of corpus texts") + scale_y_continuous(breaks=c(0, 2500, 5000, 7500, 10000, 12500, 15000, 17500))

```

# Transkribus raw data

## 3-grams from raw data

## Load data

```{r}
# Get data with Stylo
#data = stylo::load.corpus.and.parse(corpus.dir = "../dh-meier-data/output/transkribus-etudiants/raw/", features = "c", ngram.size = 3, preserve.case = FALSE)
# Get freq lists
#data = stylo::make.table.of.frequencies(corpus = data, features = unique(sort(unlist(data))), relative = FALSE)
# Write it
#write.csv(as.matrix(data), "data/transkr_raw_char3grams.csv")
data = read.csv("data/transkr_raw_char3grams.csv", header = TRUE, row.names = 1)
data = t(data)
data = data[, toKeep]
data = data[rowSums(data) > 0, ]
```

### Burrows + vector-length norm

```{r, fig.width=20, fig.height=10, dpi=45}
d = data
# Selection based on Moisl 2011
select = selection(d, z = 1.645)
select = select[,4]
# Normalisations
d = relativeFreqs(d)
# save data for robustness checks
Raw3grSave = d
d = d[select,]
d = normalisations(d)
myCAH = cluster::agnes(t(d), metric = "manhattan", method="ward")
# Save
CAHRaw3gr = myCAH
#TODO: heights
# barplot(sort(myCAH$height))
plotRaw3grams = cahPlotCol(myCAH, k = 5, main = "Characters 3-grams from raw data (Transkr)")
# somCAH = somCluster(d)
# somCAHRaw3gr = somCAH
# somplotRaw3grams = cahPlotCol(somCAH, k = 5, main = "SOM BASED - Characters 3-grams from raw data (Transkr)")
```

### Class descriptions, Wauchier and StLambert

#### Classes members
```{r}
classes = cutree(myCAH, k = 5)
classes
```
```{r, echo=FALSE}
classlabels = c("A1", "A2", "WAU", "BC_g", "BC_d")
```

#### Classes description

##### Most correlated features to the classification in general

```{r, warning=FALSE, fig.width=7.3, fig.height=7.3, out.width=1000, out.height=1000, dpi = 100}
maDesc = classesDesc(myCAH, d, k=5)
head(maDesc$quanti.var, n = 20)

myDescPlot(relativeFreqs(data)["e.i.n", , drop = FALSE], classes, type = "violinplot", main = "e.i.n", ylab = "Relative frequency", xlab = "", classlabels = classlabels)

A = myDescPlot(relativeFreqs(data)["m.m.e", , drop = FALSE], classes, type = "violinplot", main = "m.m.e", ylab = "Relative frequency", xlab = "", classlabels = classlabels)
B = myDescPlot(relativeFreqs(data)["X..a..", , drop = FALSE], classes, type = "violinplot", main = "X..a..", ylab = "Relative frequency", xlab = "", classlabels = classlabels)
C = myDescPlot(relativeFreqs(data)["o.m.m", , drop = FALSE], classes, type = "violinplot", main = "o.m.m", ylab = "Relative frequency", xlab = "", classlabels = classlabels)
D = myDescPlot(relativeFreqs(data)["d.e..", , drop = FALSE], classes, type = "violinplot", main = "d.e..", ylab = "Relative frequency", xlab = "", classlabels = classlabels)
E = myDescPlot(relativeFreqs(data)["e.i.g", , drop = FALSE], classes, type = "violinplot", main = "e.i.g", ylab = "Relative frequency", xlab = "", classlabels = classlabels)
F = myDescPlot(relativeFreqs(data)["q.i.l", , drop = FALSE], classes, type = "violinplot", main = "q.i.l", ylab = "Relative frequency", xlab = "", classlabels = classlabels)


gridExtra::grid.arrange(A,B,C,D,E,F, ncol = 2)
```

##### Features and clusters (v-test, distribution,…): Wauchier 

```{r}
nfeats = 10
values = c(head(sort(maDesc$quanti$`3`[,1], decreasing = TRUE), n = nfeats), head(sort(maDesc$quanti$`3`[,1]), n = nfeats))
classBarplot(values, title="V-test for Wauchier class", ylab = "v-test")
```

Example of two main feats of Wauchier class
```{r}
class = as.factor(classes)
levels(class) = classlabels
levels(class) = c(levels(class), "LAMB")
class["26_Ano_Leg-B_Ma_Ev_Vie_Lambert"] = "LAMB"
rf = cbind(as.data.frame(t(relativeFreqs(data))), class)
qplot(q.i.l, o.m.., colour=class, data = rf)


qplot(e.i.n, q.i.l, colour=class, data = rf)
```

##### Specificities

```{r, warning=FALSE, fig.width=14.6, fig.height=21.9, out.width=1000, out.height=1500, dpi = 100}
specifPlot(data, myCAH, k = 5)
```


# Transkribus expanded data

## Load data

```{r}
data = read.csv("data/transkr_expanded_words.csv", header = TRUE, row.names = 1)
data = t(data)
data = data[, toKeep]
data = data[rowSums(data) > 0, ]
dataWords = data
```

## Forms from expanded data

### Burrows + vector-length norm

```{r, fig.width=20, fig.height=10, dpi=45}
d = data
# Selection based on Moisl 2011
select = selection(d, z = 1.645)
select = select[,4]
# Normalisations
d = relativeFreqs(d)
# save data for robustness checks
d = d[select,]
WordsSave = d
d = normalisations(d)
myCAH = cluster::agnes(t(d), metric = "manhattan", method="ward")
# Save
CAHForms = myCAH
#TODO: heights
# barplot(sort(myCAH$height))
plotForms = cahPlotCol(myCAH, k = 5, main = "Expanded word forms (Transkr/Boudams/Pie)")

# somCAH = somCluster(d)
# somCAHForms = somCAH
# somplotForms = cahPlotCol(somCAH, k = 5, main = "SOM BASED - Expanded word forms (Transkr/Boudams/Pie)")
```

## Affixes from expanded data

```{r}
# Creating affixes database from all words
dataAffs = countAffixes(data)
```

### Burrows + vector-length norm

```{r, fig.width=20, fig.height=10, dpi=45}
d = dataAffs
# Selection based on Moisl 2011
select = selection(d, z = 1.645)
select = select[,4]
# Normalisations
d = relativeFreqs(d)
d = d[select,]
AffixesSave = d
d = normalisations(d)
myCAH = cluster::agnes(t(d), metric = "manhattan", method="ward")
# Save
CAHAffs = myCAH
#TODO: heights
# barplot(sort(myCAH$height))
plotAffixes = cahPlotCol(myCAH, k = 5, main = "Expanded affixes (Transkr/Boudams/Pie)")
# somCAH = somCluster(d)
# somCAHAffs = somCAH
# somplotAffixes = cahPlotCol(somCAH, k = 5, main = "SOM BASED - Expanded affixes (Transkr/Boudams/Pie)")
```

## Unstandardised function words from expanded data

### Create function words list

```{r}
#labels(sort(rowSums(data), decreasing = TRUE)[1:300])
# Avec ou sans pronoms ?
functionWords = source("functionWords.R")$value
dataFW = data
```

### Burrows + vector-length norm

```{r, fig.width=20, fig.height=10, dpi=45}
d = relativeFreqs(data)
d = d[functionWords,]
# save data for robustness checks
FWSave = d
d = normalisations(d)
myCAH = cluster::agnes(t(d), metric = "manhattan", method="ward")
# Save
CAHFW = myCAH
# barplot(sort(myCAH$height))
plotFW = cahPlotCol(myCAH, k = 5, main = "Function words with pronouns and auxiliaries\n(Transkr/Boudams/Pie)")
#plotCol(myCAH, main = "toto")
# somCAH = somCluster(d)
# somCAHFW = somCAH
# somplotFW = cahPlotCol(somCAH, k = 5, main = "SOM BASED - Function words")
```

# Transkribus with linguistic annotation

## POS 3-grams

```{r}
data = read.csv("data/transkr_pos3-gr.csv", header = TRUE, row.names = 1, sep = ";")
#remove total freq
data = data[, -1]
colnames(data) = gsub("^X", "", colnames(data))
colnames(data) = gsub(".decolumnized", "", colnames(data))
colnames(data) = gsub("Leg.", "Leg-", colnames(data))
data = data[, toKeep]
data = data[rowSums(data) > 0, ]
data = as.matrix(data)
```

### Burrows + vector-length norm

```{r, fig.width=20, fig.height=10, dpi=45}
dataPOS3gr = data
d = data
# Selection based on Moisl 2011
select = selection(d, z = 1.645)
write.csv(select, file="data/select_pos3gr_moisl.csv")
select = select[,4]
# Normalisations
d = relativeFreqs(d)
# save data for robustness checks
d = d[select,]
POS3grSave = d
d = normalisations(d)
myCAH = cluster::agnes(t(d), metric = "manhattan", method="ward")
# Save
CAHPOS3gr = myCAH
#TODO: heights
# barplot(sort(myCAH$height))
plotPOS3grams = cahPlotCol(myCAH, k = 5, main = "POS 3-grams (Transkr/Boudams/Pie/Pie)")
# somCAH = somCluster(d)
# somCAHPOS3gr = somCAH
# somplotPOS3grams = cahPlotCol(somCAH, k = 5, main = "SOM BASED - POS 3-grams")
```

## Lemmas


```{r}
data = read.csv("data/transkr_lemmas.csv", header = TRUE, row.names = 1, sep = ";")
#remove total freq
data = data[, -1]
colnames(data) = gsub("^X", "", colnames(data))
colnames(data) = gsub(".decolumnized", "", colnames(data))
colnames(data) = gsub("Leg.", "Leg-", colnames(data))
data = data[, toKeep]
data = data[rowSums(data) > 0, ]
data = as.matrix(data)
dataLemmas = data
```

### Burrows + vector-length norm

```{r, fig.width=20, fig.height=10, dpi=45}
d = data
# Selection based on Moisl 2011
select = selection(d, z = 1.645)
write.csv(select, file="data/select_lemmas_moisl.csv")
select = select[,4]
# Normalisations
d = relativeFreqs(d)
d = d[select,]
LemmasSave = d
d = normalisations(d)
myCAH = cluster::agnes(t(d), metric = "manhattan", method="ward")
# Save
CAHLemmas = myCAH
#TODO: heights
# barplot(sort(myCAH$height))
plotLemmas = cahPlotCol(myCAH, k = 5, main = "Lemmas (Transkr/Boudams/Pie/Pie)")
# somCAH = somCluster(d)
# somCAHLemmas = somCAH
# somplotLemmas = cahPlotCol(somCAH, k = 5, main = "SOM BASED - Lemmas")
```

## Function words from lemmas

```{r}
# Find function words
#rownames(data)[1:250]
functionLemmas = source("functionLemmas.R")$value
```

### Burrows + vector-length norm

```{r, fig.width=20, fig.height=10, dpi=45}
d = relativeFreqs(data)
d = d[functionLemmas,]
FLSave = d
d = normalisations(d)
myCAH = cluster::agnes(t(d), metric = "manhattan", method="ward")
# Save
CAHFL = myCAH
# barplot(sort(myCAH$height))
plotFL = cahPlotCol(myCAH, k = 5, main = "Function Lemmas with pronouns and auxiliaries\n(Transkr/Boudams/Pie)")
#plotCol(myCAH, main = "toto")
# somCAH = somCluster(d)
# somCAHFL = somCAH
# somplotFL = cahPlotCol(somCAH, k = 5, main = "SOM BASED - Function words (lemmas)")
```

# Affixes + POS 3-gr + Function words (lemmas)

```{r}
data = rbind(AffixesSave, POS3grSave, FLSave)
```

```{r}
d = normalisations(data)
myCAH = cluster::agnes(t(d), metric = "manhattan", method="ward")
# Save
CAHGlob = myCAH
#TODO: heights
# barplot(sort(myCAH$height))
plotGlob = cahPlotCol(myCAH, k = 5, main = "Affixes + POS 3- grams + Function words (lemmas)")
# somCAH = somCluster(d)
# somCAHGlob = somCAH
# somplotGlob = cahPlotCol(somCAH, k = 5, main = "SOM BASED - Affixes + POS 3- grams + Function words (lemmas)")
```

# Affixes + POS 3-gr + Function words (unnorm)


```{r}
data = rbind(AffixesSave, POS3grSave, FWSave)
```

```{r}
d = normalisations(data)
myCAH = cluster::agnes(t(d), metric = "manhattan", method="ward")
# Save
CAHGlob2 = myCAH
#TODO: heights
# barplot(sort(myCAH$height))
plotGlob2 = cahPlotCol(myCAH, k = 5, main = "Affixes + POS 3- grams + Function words (unnorm.)")
# somCAH = somCluster(d)
# somCAHGlob2 = somCAH
# somplotGlob2 = cahPlotCol(somCAH, k = 5, main = "SOM BASED - Affixes + POS 3- grams + Function words (unnorm.)")
```


### Class descriptions, Wauchier and StLambert

#### Classes members
```{r}
classes = cutree(myCAH, k = 5)
classes
```
```{r, echo=FALSE}
classlabels = c("A1", "A2B", "WAU", "C", "AndrCathAntechr")
```

#### Classes description

##### Most correlated features to the classification in general

```{r, warning=FALSE, fig.width=7.3, fig.height=7.3, out.width=1000, out.height=1000, dpi = 100}
maDesc = classesDesc(myCAH, d, k=5)
head(maDesc$quanti.var, n = 20)

A = myDescPlot(relativeFreqs(data)["mme^", , drop = FALSE], classes, type = "violinplot", main = "mme^", ylab = "Relative frequency", xlab = "", classlabels = classlabels)
B = myDescPlot(relativeFreqs(data)["que", , drop = FALSE], classes, type = "violinplot", main = "que", ylab = "Relative frequency", xlab = "", classlabels = classlabels)
C = myDescPlot(relativeFreqs(data)["CONcoo PROper VERcjg", , drop = FALSE], classes, type = "violinplot", main = "CONcoo.PROper.VERcjg", ylab = "Relative frequency", xlab = "", classlabels = classlabels)
D = myDescPlot(relativeFreqs(data)["ls_", , drop = FALSE], classes, type = "violinplot", main = "ls_", ylab = "Relative frequency", xlab = "", classlabels = classlabels)
E = myDescPlot(relativeFreqs(data)["_fa", , drop = FALSE], classes, type = "violinplot", main = "_fa", ylab = "Relative frequency", xlab = "", classlabels = classlabels)
F = myDescPlot(relativeFreqs(data)["$fai", , drop = FALSE], classes, type = "violinplot", main = "$fai", ylab = "Relative frequency", xlab = "", classlabels = classlabels)
gridExtra::grid.arrange(A,B,C,D,E,F, ncol = 2)
```

##### Features and clusters (v-test, distribution,…): Wauchier 

```{r}
nfeats = 10
values = c(head(sort(maDesc$quanti$`3`[,1], decreasing = TRUE), n = nfeats), head(sort(maDesc$quanti$`3`[,1]), n = nfeats))
classBarplot(values, title="V-test for Wauchier class", ylab = "v-test")
```

Example of two main feats of Wauchier class
```{r}
class = as.factor(classes)
levels(class) = classlabels
levels(class) = c(levels(class), "LAMB")
class["26_Ano_Leg-B_Ma_Ev_Vie_Lambert"] = "LAMB"
#NB: 
rf = cbind(as.data.frame(t(relativeFreqs(data))), class)
qplot(qil, om_, colour=class, data = rf)
```

##### Specificities

```{r, warning=FALSE, fig.width=14.6, fig.height=21.9, out.width=1000, out.height=1500, dpi = 100}
data = rbind(dataAffs, dataPOS3gr, dataFW)
specifPlot(data, myCAH, k = 5)
```



# Affixes + POS 3-gr + Function words (both)

```{r}
data = rbind(AffixesSave, POS3grSave, FWSave, FLSave)
```

```{r}
d = normalisations(data)
myCAH = cluster::agnes(t(d), metric = "manhattan", method="ward")
# Save
CAHGlob3 = myCAH
#TODO: heights
# barplot(sort(myCAH$height))
plotGlob3 = cahPlotCol(myCAH, k = 5, main = "Affixes + POS 3- grams + Function words (both)")
# somCAH = somCluster(d)
# somCAHGlob3 = somCAH
# somplotGlob3 = cahPlotCol(somCAH, k = 5, main = "SOM BASED - Affixes + POS 3- grams + Function words (unnorm.)")
```

# Exp. word-forms+lemmas


```{r}
data = rbind(LemmasSave, WordsSave)
```

```{r}
d = normalisations(data)
myCAH = cluster::agnes(t(d), metric = "manhattan", method="ward")
# Save
CAHWordsLemmas = myCAH
#TODO: heights
# barplot(sort(myCAH$height))
plotWordsLemmas = cahPlotCol(myCAH, k = 5, main = "Word forms + lemmas")
# somCAH = somCluster(d)
# somCAHWordsLemmas = somCAH
# somplotWordsLemmas = cahPlotCol(somCAH, k = 5, main = "SOM BASED - Word forms + lemmas")
```

### Class descriptions, Wauchier and StLambert

#### Classes members
```{r}
classes = cutree(myCAH, k = 5)
classes
```
```{r, echo=FALSE}
classlabels = c("A1+AndrCath", "A2", "B", "WAU", "C")
```

#### Classes description

##### Most correlated features to the classification in general

```{r, warning=FALSE, fig.width=7.3, fig.height=7.3, out.width=1000, out.height=1000, dpi = 100}
maDesc = classesDesc(myCAH, d, k=5)
head(maDesc$quanti.var, n = 20)

A = myDescPlot(relativeFreqs(data)["que", , drop = FALSE], classes, type = "violinplot", main = "que", ylab = "Relative frequency", xlab = "", classlabels = classlabels)
B = myDescPlot(relativeFreqs(data)["qil", , drop = FALSE], classes, type = "violinplot", main = "qil", ylab = "Relative frequency", xlab = "", classlabels = classlabels)
C = myDescPlot(relativeFreqs(data)["dont", , drop = FALSE], classes, type = "violinplot", main = "dont", ylab = "Relative frequency", xlab = "", classlabels = classlabels)
D = myDescPlot(relativeFreqs(data)["faire", , drop = FALSE], classes, type = "violinplot", main = "faire", ylab = "Relative frequency", xlab = "", classlabels = classlabels)
E = myDescPlot(relativeFreqs(data)["nez", , drop = FALSE], classes, type = "violinplot", main = "nez", ylab = "Relative frequency", xlab = "", classlabels = classlabels)
F = myDescPlot(relativeFreqs(data)["un", , drop = FALSE], classes, type = "violinplot", main = "un", ylab = "Relative frequency", xlab = "", classlabels = classlabels)
gridExtra::grid.arrange(A,B,C,D,E,F, ncol = 2)
```

##### Features and clusters (v-test, distribution,…): Wauchier 

```{r}
nfeats = 10
values = c(head(sort(maDesc$quanti$`4`[,1], decreasing = TRUE), n = nfeats), head(sort(maDesc$quanti$`4`[,1]), n = nfeats))
classBarplot(values, title="V-test for Wauchier class", ylab = "v-test")
```

Example of two main feats of Wauchier class
```{r}
class = as.factor(classes)
levels(class) = classlabels
levels(class) = c(levels(class), "LAMB")
class["26_Ano_Leg-B_Ma_Ev_Vie_Lambert"] = "LAMB"
#NB: 
rf = cbind(as.data.frame(t(relativeFreqs(data))), class)
rf = rf[, c("ensemble", "qil", "que")]
# Two main of Wauchier class
qplot(qil, ensemble, colour=class, data = rf)

# TWO MOST CORRELATED TO CLUSTERS
qplot(qil, que, colour=class, data = rf)
```

##### Specificities

```{r, warning=FALSE, fig.width=14.6, fig.height=21.9, out.width=1000, out.height=1500, dpi = 100}
#TODO: fix to take only the one that have been actually selected by the Moisl formula
data = rbind(dataLemmas, dataWords)
specifPlot(data, myCAH, k = 5)
```



# Plots and tables

## Reference results on the three feature sets

```{r, warning=FALSE, fig.width=14.6, fig.height=21.9, out.width=1000, out.height=1500, dpi = 100}
gridExtra::grid.arrange(plotRaw3grams, plotGlob2, plotWordsLemmas, ncol = 1)
```

## Complementary results

```{r, warning=FALSE, fig.width=14.6, fig.height=21.9, out.width=1000, out.height=1500, dpi = 100}
#featlabel = "features of ME ±2σ with conf. > 90%"
#A = cahPlotCol(CAHLemma, main = "A", xlab = paste( ncol(CAHLemma$data), featlabel), k = 6, lrect = -12)
# B = cahPlotCol(CAHRhyme, main = "B", xlab = paste( ncol(CAHRhyme$data), featlabel), k = 6, lrect = -7, ylab = " ")
# C = cahPlotCol(CAHAllWords, main = "C", xlab = paste( ncol(CAHAllWords$data), featlabel), k = 6, ylab = " ")
# D = cahPlotCol(CAHAffs, main = "D", xlab = paste( ncol(CAHAffs$data), featlabel), k = 6, ylab = " ")
# E = cahPlotCol(CAHPOS3gr, main = "E", xlab = paste( ncol(CAHPOS3gr$data), featlabel), k = 6, lrect = -12 , ylab = " ")
# F = cahPlotCol(CAHmfw, main = "F", k = 6, lrect = -5, ylab = " ")
# gridExtra::grid.arrange(A, B, C, D, E, F, ncol = 2)
gridExtra::grid.arrange(plotAffixes, plotFW, plotFL, plotPOS3grams, plotForms, plotLemmas, ncol = 2)
```


## Comparison three alternatives, FS2
```{r}
gridExtra::grid.arrange(plotGlob, plotGlob2, plotGlob3, ncol = 1)
```


<!-- ## Analyses -->

<!-- ```{r, warning=FALSE, fig.width=14.6, fig.height=21.9, out.width=1000, out.height=1500, dpi = 100} -->
<!-- #featlabel = "features of ME ±2σ with conf. > 90%" -->
<!-- #A = cahPlotCol(CAHLemma, main = "A", xlab = paste( ncol(CAHLemma$data), featlabel), k = 6, lrect = -12) -->
<!-- # B = cahPlotCol(CAHRhyme, main = "B", xlab = paste( ncol(CAHRhyme$data), featlabel), k = 6, lrect = -7, ylab = " ") -->
<!-- # C = cahPlotCol(CAHAllWords, main = "C", xlab = paste( ncol(CAHAllWords$data), featlabel), k = 6, ylab = " ") -->
<!-- # D = cahPlotCol(CAHAffs, main = "D", xlab = paste( ncol(CAHAffs$data), featlabel), k = 6, ylab = " ") -->
<!-- # E = cahPlotCol(CAHPOS3gr, main = "E", xlab = paste( ncol(CAHPOS3gr$data), featlabel), k = 6, lrect = -12 , ylab = " ") -->
<!-- # F = cahPlotCol(CAHmfw, main = "F", k = 6, lrect = -5, ylab = " ") -->
<!-- # gridExtra::grid.arrange(A, B, C, D, E, F, ncol = 2) -->
<!-- gridExtra::grid.arrange(plotRaw3grams, plotForms, plotAffixes, plotFW, plotLemmas, plotFL, plotPOS3grams, plotGlob, ncol = 2) -->
<!-- ``` -->


<!-- ```{r, warning=FALSE, fig.width=14.6, fig.height=21.9, out.width=1000, out.height=1500, dpi = 100} -->
<!-- gridExtra::grid.arrange(somplotRaw3grams, somplotForms, somplotAffixes, somplotFW, somplotLemmas, somplotFL, somplotPOS3grams, somplotGlob, ncol = 2) -->
<!-- ``` -->

## Robustness

```{r}
cahList = list(raw3grams = CAHRaw3gr, Affs = CAHAffs, FunctWords = CAHFW, FunctLemm = CAHFL, POS3gr = CAHPOS3gr, FWPOSandAffs = CAHGlob2, Forms = CAHForms,  Lemmas = CAHLemmas, WordsLemmas = CAHWordsLemmas)
#compareHC(cahList, k = 5)

benchmark = benchmarkHC(CAHRaw3gr, cahList, k = 5)
round(benchmark, digits = 2)

# # Now with SOM
# cahSOMList = list(raw3grams = somCAHRaw3gr, Affs = somCAHAffs, FunctLemm = somCAHFL, POS3gr = somCAHPOS3gr, FLPOSandAffs = somCAHGlob, FWPOSandAffs = somCAHGlob2, FLFWPOSandAffs = somCAHGlob3, Forms = somCAHForms,  Lemmas = somCAHLemmas, WordsLemmas = somCAHWordsLemmas, UnnormFW = somCAHFW)
# 
# benchmark = benchmarkHC(CAHRaw3gr, cahSOMList, k = 5)
# round(benchmark, digits = 2)
```

## Volatility index

## Ref analyses

```{r}
# ONLY on the three reference analyses
cahList = list(raw3grams = CAHRaw3gr,  FWPOSandAffs = CAHGlob2, WordsLemmas = CAHWordsLemmas)

vol = volatility(cahList, k = 5)

volRef = merge(round(vol, digits = 2), nwords, by="row.names", all.x=TRUE, all.y=FALSE)

volRef[order(volRef[, "V_i"]), ]

# see if there is a correlation
reg = lm(volRef[, 3] ~ volRef[, 2])
summary(reg)
plot(volRef[, 2], volRef[, 3])
abline(reg)

# Et la distrib des VI
boxplot(volRef[, 2])
hist(volRef[, 2])
```

## Supplementary analyses

```{r}
# ONLY on the three reference analyses
cahList = list(Affs = CAHAffs, FunctWords = CAHFW, FunctLemm = CAHFL, POS3gr = CAHPOS3gr, Forms = CAHForms,  Lemmas = CAHLemmas)

vol = volatility(cahList, k = 5)

volSuppl = merge(round(vol, digits = 2), nwords, by="row.names", all.x=TRUE, all.y=FALSE)

volSuppl[order(volSuppl[, "V_i"]), ]

# see if there is a correlation
reg = lm(volSuppl[, 3] ~ volSuppl[, 2])
summary(reg)
plot(volSuppl[, 2], volSuppl[, 3])
abline(reg)

# Et la distrib des VI
boxplot(volSuppl[, 2])
hist(volSuppl[, 2])
```

## Formatted table with both

```{r}
out = merge(volRef, volSuppl, by="row.names", all.x=TRUE, all.y=TRUE)
rownames(out) = out[, 2]
out = out[, c(4, 3, 6)]
colnames(out) = c("NWords", "V_iRef", "V_iSuppl")
out[order(out[, 2]),]
```

```{r}
# First, transform data
volRegr = rbind( data.frame(NWords = volRef[, 3], V_i = volRef[, 2], type = "Ref"), 
                 data.frame(NWords = volSuppl[, 3], V_i = volSuppl[, 2], type = "Suppl"))


library(ggpmisc)

ggplot(volRegr, aes(NWords, V_i, shape=type, colour=type, fill=type)) + geom_smooth(method="lm") +
  geom_point(size=3) + theme_bw() +
 # ggpmisc::stat_poly_eq(formula = quote(V_i) ~ quote(NWords), aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), parse = TRUE) 
  ggpmisc::stat_fit_glance(method = 'lm', aes(label = paste0('p = ', round(..p.value.., 3), " Adj. R² = ", round(..adj.r.squared.., 3))))
```


### With all 
```{r}
vol = volatility(cahList, k = 5)
out = merge(round(vol, digits = 2), nwords, by="row.names", all.x=TRUE, all.y=FALSE)
out[order(out[, "V_i"]), ]

# see if there is a correlation
reg = lm(out[, 3] ~ out[, 2])
summary(reg)
plot(out[, 2], out[, 3])
abline(reg)

# Et la distrib des VI
boxplot(out[, 2])
hist(out[, 2])
```


# Controlling for pipeline bias


```{r}
RefcahList = list(raw3grams = CAHRaw3gr, Affs = CAHAffs, FunctWords = CAHFW, FunctLemm = CAHFL, POS3gr = CAHPOS3gr, FWPOSandAffs = CAHGlob2, Forms = CAHForms,  Lemmas = CAHLemmas, WordsLemmas = CAHWordsLemmas)
##CAREFUL ###
####TEMPORARY FIX - DO REMOVE ME LATER#####
#toKeepBis = toKeep[!toKeep == "60_Ano_Leg-B_NA_NA_NA_Antechriste"]
# Redo base results without Antechrist
#RefcahListBis = replicateAnalysis(toKeepBis, "data/transkr_raw_char3grams.csv", "data/transkr_expanded_words.csv", "data/transkr_pos3-gr.csv", "data/transkr_lemmas.csv", functionWords, functionLemmas)
# 1. get Students analysis list
#StudentsResults = replicateAnalysis(toKeepBis, "data/transkr_student_raw_char3grams.csv", "data/transkr_student_expanded_words.csv", "data/transkr_student_pos3-gr.csv", "data/transkr_student_lemmas.csv", functionWords, functionLemmas)
StudentsResults = replicateAnalysis(toKeep, "data/transkr_student_raw_char3grams.csv", "data/transkr_student_expanded_words.csv", "data/transkr_student_pos3-gr.csv", "data/transkr_student_lemmas.csv", functionWords, functionLemmas)

# 2. perform comparison
comp1 = compareReplications(RefcahList, StudentsResults, k = 5)

# 3. get Kraken analysis list
KrakenResults = replicateAnalysis(toKeep, "data/kraken_nospace_raw_char3grams.csv", "data/kraken_nospace_expanded_words.csv", "data/kraken_nospace_pos3-gr.csv", "data/kraken_nospace_lemmas.csv", functionWords, functionLemmas)

# 4. perform comparison
comp2 = compareReplications(RefcahList, KrakenResults, k = 5)

# 5. merge and output
out = cbind(comp1, comp2)
colnames(out) = c("Students", "Kraken")

refs = c("raw3grams", "FWPOSandAffs", "WordsLemmas")
suppl = rownames(out)[!rownames(out) %in% refs]
# Geom mean all
out = rbind(out, exp(colMeans(log(out))))
# Geom mean refs
out = rbind(out, exp(colMeans(log(out[refs, ]))))
# Geom mean suppl
out = rbind(out, exp(colMeans(log(out[suppl, ]))))
rownames(out)[(length(rownames(out))-2):length(rownames(out))] =  c("geom mean all", "geom mean refs", "geom mean suppl")
round(out, 2)
```



